{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment 3\n",
    "\n",
    "Implement from scratch an RBM and apply it to DSET3. The RBM should be implemented fully by you (both CD-1 training and inference steps) but you are free to use library functions for the rest (e.g. image loading and management, etc.).\n",
    "\n",
    "1.     Train an RBM with a number of hidden neurons selected by you (single layer) on the MNIST data (use the training set split provided by the website).\n",
    "\n",
    "2.     Use the trained RBM to encode a selection of test images (e.g. using one per digit type) using the corresponding activation of the hidden neurons.\n",
    "\n",
    "3.    Train a simple classifier (e.g. any simple classifier in scikit) to recognize the MNIST digits using as inputs their encoding obtained at step 2. Use the standard training/test split. Show a performance metric of your choice in the presentation/handout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import idx2numpy\n",
    "tr_images=idx2numpy.convert_from_file('./dataset/train-images.idx3-ubyte')\n",
    "tr_labels=idx2numpy.convert_from_file('./dataset/train-labels.idx1-ubyte')\n",
    "ts_images=idx2numpy.convert_from_file('./dataset/t10k-images.idx3-ubyte')\n",
    "ts_labels=idx2numpy.convert_from_file('./dataset/t10k-labels.idx1-ubyte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM:\n",
    "    def __init__(self,visible_size,hidden_size):\n",
    "\n",
    "        self.visible_bias= np.zeros(visible_size,dtype='float64')\n",
    "        self.hidden_bias= np.zeros(hidden_size,dtype='float64')\n",
    "\n",
    "        self.weights=np.random.normal(scale=0.01,size=(visible_size,hidden_size))\n",
    "        print(f\"buildinig a RBM with {visible_size} visible units and {hidden_size} hidden units\")\n",
    "\n",
    "    def _sample(self,prob):\n",
    "        return (prob > np.random.rand(*prob.shape)).astype(np.float64)\n",
    "    def sample_hidden(self,v):\n",
    "        ha_prob= sigmoid(v@self.weights+self.hidden_bias)\n",
    "        ha_states= self._sample(ha_prob)\n",
    "        return ha_prob,ha_states\n",
    "    def sample_visible(self,h):\n",
    "        recon_prob=sigmoid(h@self.weights.T+self.visible_bias)\n",
    "        recon_act= self._sample(recon_prob)\n",
    "        return recon_prob,recon_act\n",
    "    def train(self,values,eta=0.01,epochs=100,batch_size=64):\n",
    "        print(f\"training started with {values.shape[0]} samples \\nepochs={epochs}\\t batch size={batch_size}\\t learning rate={eta}\")\n",
    "        for e in range(epochs):\n",
    "            for i in range(0,values.shape[0],batch_size):\n",
    "                # clamp data as input\n",
    "                clamped_data= self._sample(values[i:i+batch_size])\n",
    "                #sample h given v\n",
    "                ha_prob,ha_states=self.sample_hidden(clamped_data)\n",
    "                #calculate wake part\n",
    "                wake=clamped_data.T@ha_prob\n",
    "                #sample v given h\n",
    "                recon_prob,recon_act=self.sample_visible(ha_states)\n",
    "                active_prob=sigmoid(recon_act@self.weights+ self.hidden_bias)\n",
    "                #calculate dream part\n",
    "                dream=recon_act.T@active_prob\n",
    "                delta_w=(wake-dream)/batch_size\n",
    "                delta_bh = (np.mean(ha_prob, axis=0) - np.mean(active_prob, axis=0))\n",
    "                delta_bv = (np.mean(clamped_data, axis=0) - np.mean(recon_act, axis=0))\n",
    "\n",
    "                self.weights+=eta*delta_w\n",
    "                self.hidden_bias+=eta*delta_bh\n",
    "                self.visible_bias+=eta*delta_bv\n",
    "            clamped_data= self._sample(values)\n",
    "            ha_prob,ha_states=self.sample_hidden(clamped_data)\n",
    "            recon_prob,recon_act=self.sample_visible(ha_states)\n",
    "            print(f\"epoch no.{e+1} reconstruction error: {np.mean((clamped_data-recon_act)**2)}\")\n",
    "    def encode(self,data):\n",
    "        #sample h given v\n",
    "        _,ha_states=self.sample_hidden(data)\n",
    "        return ha_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buildinig a RBM with 784 visible units and 50 hidden units\n",
      "training started with 60000 samples and 10 epochs and batch size of 64\n",
      "epoch no.1 reconstruction error: 0.09015204081632654\n",
      "epoch no.2 reconstruction error: 0.08310070153061225\n",
      "epoch no.3 reconstruction error: 0.08007946428571429\n",
      "epoch no.4 reconstruction error: 0.07856607142857143\n",
      "epoch no.5 reconstruction error: 0.07730799319727891\n",
      "epoch no.6 reconstruction error: 0.07683022959183673\n",
      "epoch no.7 reconstruction error: 0.07616315901360544\n",
      "epoch no.8 reconstruction error: 0.07548830782312925\n",
      "epoch no.9 reconstruction error: 0.07488426870748299\n",
      "epoch no.10 reconstruction error: 0.07443101615646258\n"
     ]
    }
   ],
   "source": [
    "rbm=RBM(28*28,50)\n",
    "\n",
    "training=tr_images.reshape((-1,28*28))\n",
    "#binarize the data\n",
    "training=(training>127).astype(np.float64)\n",
    "rbm.train(training,\n",
    "          eta=0.2,\n",
    "          epochs=10,\n",
    "          batch_size=64\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=ts_images.reshape((-1,28*28))\n",
    "test=(test>127).astype(np.float64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_train=rbm.encode(training)\n",
    "h_test=rbm.encode(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5391\n",
      "0.6894\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "nb=GaussianNB().fit(training,tr_labels)\n",
    "pred=nb.predict(test)\n",
    "print(accuracy_score(ts_labels,pred))\n",
    "nb=GaussianNB().fit(h_train,tr_labels)\n",
    "pred=nb.predict(h_test)\n",
    "print(accuracy_score(ts_labels,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mirda\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.917\n",
      "0.8797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mirda\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "mlp=LogisticRegression().fit(training,tr_labels)\n",
    "pred=mlp.predict(test)\n",
    "print(accuracy_score(ts_labels,pred))\n",
    "mlp=LogisticRegression().fit(h_train,tr_labels)\n",
    "pred=mlp.predict(h_test)\n",
    "print(accuracy_score(ts_labels,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.958\n",
      "0.9218\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=5).fit(training, tr_labels)\n",
    "pred=neigh.predict(test)\n",
    "print(accuracy_score(ts_labels,pred))\n",
    "neigh=KNeighborsClassifier(n_neighbors=5).fit(h_train,tr_labels)\n",
    "pred=neigh.predict(h_test)\n",
    "print(accuracy_score(ts_labels,pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
