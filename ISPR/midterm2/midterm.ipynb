{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment 3\n",
    "\n",
    "Implement from scratch an RBM and apply it to DSET3. The RBM should be implemented fully by you (both CD-1 training and inference steps) but you are free to use library functions for the rest (e.g. image loading and management, etc.).\n",
    "\n",
    "1.     Train an RBM with a number of hidden neurons selected by you (single layer) on the MNIST data (use the training set split provided by the website).\n",
    "\n",
    "2.     Use the trained RBM to encode a selection of test images (e.g. using one per digit type) using the corresponding activation of the hidden neurons.\n",
    "\n",
    "3.    Train a simple classifier (e.g. any simple classifier in scikit) to recognize the MNIST digits using as inputs their encoding obtained at step 2. Use the standard training/test split. Show a performance metric of your choice in the presentation/handout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import idx2numpy\n",
    "tr_images=idx2numpy.convert_from_file('./dataset/train-images.idx3-ubyte')\n",
    "tr_labels=idx2numpy.convert_from_file('./dataset/train-labels.idx1-ubyte')\n",
    "ts_images=idx2numpy.convert_from_file('./dataset/t10k-images.idx3-ubyte')\n",
    "ts_labels=idx2numpy.convert_from_file('./dataset/t10k-labels.idx1-ubyte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM:\n",
    "    def __init__(self,visible_size,hidden_size):\n",
    "        self.visible_neurons= np.array(visible_size,dtype='float64')\n",
    "        self.hidden_neurons= np.array(hidden_size,dtype='float64')\n",
    "\n",
    "        self.visible_bias= np.zeros(visible_size,dtype='float64')\n",
    "        self.hidden_bias= np.zeros(hidden_size,dtype='float64')\n",
    "\n",
    "        self.weights=np.random.normal(loc=0,scale=0.01,size=(visible_size,hidden_size))\n",
    "    \n",
    "    def learn(self,values,eta=0.01):\n",
    "        # clamp data as input\n",
    "        clamped_data= (values > np.random.rand(*values.shape)).astype(int)\n",
    "        #sample h given v\n",
    "        ha_prob= sigmoid(clamped_data@self.weights+self.hidden_bias)\n",
    "        ha_states= (ha_prob > np.random.rand(*ha_prob.shape)).astype(int)\n",
    "\n",
    "        #calculate wake part\n",
    "        wake=clamped_data.T@ha_prob\n",
    "        #sample v given h\n",
    "        recon_prob=sigmoid(ha_states@self.weights.T+self.visible_bias)\n",
    "        recon_act= (recon_prob > np.random.rand(*recon_prob.shape)).astype(int)\n",
    "        #calculate probability for dream part\n",
    "        active_prob=sigmoid(recon_act@self.weights+ self.hidden_bias)\n",
    "        #calculate dream part\n",
    "        dream=recon_act.T@active_prob\n",
    "\n",
    "        # update model parameters\n",
    "        batch_size=np.float64(len(values))\n",
    "\n",
    "        delta_w=(wake-dream)/batch_size\n",
    "        delta_bh=( np.sum(ha_prob) - np.sum(recon_prob) )/batch_size\n",
    "        delta_bv=( np.sum(clamped_data) - np.sum(recon_act) )/batch_size\n",
    "\n",
    "        self.weights+=eta*delta_w\n",
    "        self.hidden_bias+=eta*delta_bh\n",
    "        self.visible_bias+=eta*delta_bv\n",
    "        #calculate and return reconstruction error\n",
    "        return np.sum((clamped_data-recon_act)**2)/batch_size\n",
    "    def train(self,data,epochs=100,learning_rate=0.01):\n",
    "        print(f\"begin training with {len(data)} elements\")\n",
    "        for i in range(0,epochs):\n",
    "            rec_error=self.learn(data,learning_rate)\n",
    "            print(f\"epoch no.{i+1}, reconstruction error {rec_error}\")\n",
    "    def encode(self,data):\n",
    "        #clamped_data= (data > np.random.rand(*data.shape)).astype(np.float64)\n",
    "        #sample h given v\n",
    "        ha_prob= sigmoid(data@self.weights+self.hidden_bias)\n",
    "        ha_states= (ha_prob > np.random.rand(*ha_prob.shape)).astype(np.float64)\n",
    "        return ha_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training with 60000 elements\n",
      "epoch no.1, reconstruction error 391.5600166666667\n",
      "epoch no.2, reconstruction error 343.10215\n",
      "epoch no.3, reconstruction error 308.3268166666667\n",
      "epoch no.4, reconstruction error 282.57913333333335\n",
      "epoch no.5, reconstruction error 263.1804333333333\n",
      "epoch no.6, reconstruction error 248.08178333333333\n",
      "epoch no.7, reconstruction error 236.05825\n",
      "epoch no.8, reconstruction error 226.30575\n",
      "epoch no.9, reconstruction error 217.99255\n",
      "epoch no.10, reconstruction error 211.00045\n",
      "epoch no.11, reconstruction error 205.10296666666667\n",
      "epoch no.12, reconstruction error 199.61708333333334\n",
      "epoch no.13, reconstruction error 194.7347\n",
      "epoch no.14, reconstruction error 190.20548333333332\n",
      "epoch no.15, reconstruction error 185.84405\n",
      "epoch no.16, reconstruction error 181.72921666666667\n",
      "epoch no.17, reconstruction error 177.93091666666666\n",
      "epoch no.18, reconstruction error 174.26603333333333\n",
      "epoch no.19, reconstruction error 170.98075\n",
      "epoch no.20, reconstruction error 167.80456666666666\n"
     ]
    }
   ],
   "source": [
    "epochs=100\n",
    "rbm=RBM(28*28,500)\n",
    "training=tr_images.reshape((-1,28*28))\n",
    "#binarizing data\n",
    "training_data=((training-training.min())/(training.max()-training.min()) > 0.5).astype(np.float64)\n",
    "rbm.train(training_data,20,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of samples per single digit\n",
    "digit_samples=100\n",
    "\n",
    "idx=np.array([ np.where(ts_labels == i)[0][:digit_samples] for i in range(10)]).reshape((-1))\n",
    "test_data=ts_images.reshape((-1,28*28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_training_data=rbm.encode(test_data[idx])\n",
    "h_test_data=rbm.encode(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb=GaussianNB().fit(training,tr_labels)\n",
    "pred=nb.predict(test_data[idx])\n",
    "len(pred==ts_labels[idx])/len(idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(random_state=1, max_iter=300).fit(training,tr_labels)\n",
    "pred=mlp.predict(test_data[idx])\n",
    "len(pred==ts_labels[idx])/len(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=9).fit(training, tr_labels)\n",
    "pred=knn.predict(test_data[idx])\n",
    "len(pred==ts_labels[idx])/len(idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
